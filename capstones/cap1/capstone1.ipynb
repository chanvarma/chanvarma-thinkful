{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:34.599080Z",
     "start_time": "2019-07-16T22:00:34.594772Z"
    }
   },
   "outputs": [],
   "source": [
    "#re.findall('\\(.*?\\)',b1)\n",
    "#re.findall('\\(.*?\\)',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:46:17.025490Z",
     "start_time": "2019-07-17T00:46:16.819798Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from goodreads import client\n",
    "gc = client.GoodreadsClient('9addHIFaPJmit7dzC5ZA', 'iDXvx13Rnt1iJkWOxRkSh9wLnbFWmMNgCUMFLJmLPo')\n",
    "\n",
    "from imdb import IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.303190Z",
     "start_time": "2019-07-16T22:00:57.297382Z"
    }
   },
   "outputs": [],
   "source": [
    "wikipages = ['https://en.wikipedia.org/wiki/List_of_children%27s_books_made_into_feature_films?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(0%E2%80%939,_A%E2%80%93C)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(D%E2%80%93J)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(K%E2%80%93R)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(S%E2%80%93Z)?oldformat=true'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.317754Z",
     "start_time": "2019-07-16T22:00:57.306805Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_rows(page_soup):\n",
    "    \"\"\"\n",
    "    Method extracts row elements from the soup tags of individual \n",
    "    list pages (A - F, H - J, etc.) and appends them to the `rows` \n",
    "    list.\n",
    "    \n",
    "    Args:\n",
    "        page_soup: (BeautifulSoup tag) soup for list page.\n",
    "    \"\"\"\n",
    "    \n",
    "    global rows\n",
    "    \n",
    "    tables = page_soup.find_all('table', {'class': 'wikitable'})\n",
    "\n",
    "    for alphabet in tables:\n",
    "        rows += alphabet.findAll('tr')\n",
    "    \n",
    "    print(\"Tables added: {}, Rows added: {}\".format(len(tables), len(rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:10:43.029078Z",
     "start_time": "2019-07-17T00:10:43.025333Z"
    }
   },
   "outputs": [],
   "source": [
    "def working_wiki_link(wiki_link):\n",
    "    \"\"\"\n",
    "    Converts relative URLs to global URLs.\n",
    "    \"\"\"\n",
    "    if '/wiki/' in wiki_link:\n",
    "        return 'https://en.wikipedia.org' + wiki_link\n",
    "    return wiki_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T23:59:53.818658Z",
     "start_time": "2019-07-16T23:59:53.806097Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adaptations(book_title, href_list):\n",
    "    \"\"\"\n",
    "    Parses through list of movies associated with a specific `book_title`,\n",
    "    adds movies to `movie_book_dict`, and returns list of movies.\n",
    "    Adds year to the movie title if information available. \n",
    "    \n",
    "    Args:\n",
    "        book_title: (str) name of original book.\n",
    "        href_list: (list) Result of findAll('a') on the movies column.\n",
    "        \n",
    "    Returns:\n",
    "        adaptations: List of movie title names.\n",
    "    \"\"\"\n",
    "    adaptations = []\n",
    "    \n",
    "    if len(href_list) == 1:\n",
    "        adaptations.append(href_list[0]['title'])\n",
    "        return adaptations\n",
    "        \n",
    "    for index, tag in enumerate(href_list):\n",
    "        year_search = re.search(r'\\d\\d\\d\\d', tag['href'])\n",
    "        \n",
    "        if year_search is not None:  #There is a 4 digit number in the title\n",
    "            year_search = year_search.group()\n",
    "        \n",
    "            if year_search not in tag['title']:\n",
    "                version = tag['title'] + ' (' + year_search + ')'\n",
    "            else:\n",
    "                version = tag['title']\n",
    "            \n",
    "            adaptations.append(version)\n",
    "            movie_book_dict[working_wiki_link(tag['href'])] = {'movie_title': version, \n",
    "                                                              'book': book_title,\n",
    "                                                              'imdb_no': '', 'usable': ''}\n",
    "        \n",
    "        else:\n",
    "            version = tag['title']\n",
    "            adaptations.append(version)\n",
    "            movie_book_dict[working_wiki_link(tag['href'])] = {'movie_title': version, \n",
    "                                                              'book': book_title,\n",
    "                                                              'imdb_no': '', 'usable': ''}\n",
    "\n",
    "    \n",
    "    return adaptations\n",
    "\n",
    "def clean_adaptations(adaptations):\n",
    "    \"\"\"\n",
    "    Makes sure the list of adaptations doesn't contain TV series or miniseries.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned = []\n",
    "    \n",
    "    for title in adaptations:\n",
    "        if 'TV' in title or 'miniseries' in title:\n",
    "            continue\n",
    "        if 'page does not exist' in title:\n",
    "            continue\n",
    "        else:\n",
    "            cleaned.append(title)\n",
    "            \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:12:59.541912Z",
     "start_time": "2019-07-16T22:12:59.531429Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_book_film_dict():\n",
    "    \"\"\"\n",
    "    Method parses newly updated rows for book/film title, book author,\n",
    "    number of adaptions, and list of adaptations, and adds them to the\n",
    "    `book_film_dict` as a nested dictionary. \n",
    "    global sum_adaptations\n",
    "    \"\"\"\n",
    "    global sum_adaptations\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.findAll('td')\n",
    "\n",
    "        try:\n",
    "            if (len(cols[0].findAll('a')) == 2) and (cols[1].find('a') is not None):\n",
    "                series = cols[0].text.replace('\\n', '').split(',')[0]\n",
    "\n",
    "                book_title = cols[0].findAll('a')[0]['title']\n",
    "                author = cols[0].findAll('a')[-1]['title']\n",
    "\n",
    "                book_wiki_url = working_wiki_link(cols[0].findAll('a')[0]['href'])\n",
    "\n",
    "                try:\n",
    "                    adaptations = clean_adaptations(get_adaptations(book_title, cols[1].findAll('a')))\n",
    "                except KeyError:\n",
    "                    adaptations = []\n",
    "                    pass\n",
    "\n",
    "                sum_adaptations += len(adaptations)\n",
    "\n",
    "                book_film_dict_all[series] = {'author': author,\n",
    "                                            'book_title': book_title,\n",
    "                                            'book_wiki_url': book_wiki_url,\n",
    "                                            'count': len(adaptations),\n",
    "                                            'adaptations': adaptations,\n",
    "                                            'isbn': '', 'oclc':'', 'valid_identifier': ''}\n",
    "\n",
    "        except IndexError or KeyError:\n",
    "            pass\n",
    "        \n",
    "    print(\"No. of rows/original books in dict: {}, No. of adaptations: {} \\n\"\n",
    "          .format(len(book_film_dict_all), sum_adaptations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:00:08.591348Z",
     "start_time": "2019-07-17T00:00:04.577098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables added: 25, Rows added: 376\n",
      "No. of rows/original books in dict: 259, No. of adaptations: 754 \n",
      "\n",
      "Tables added: 3, Rows added: 798\n",
      "No. of rows/original books in dict: 553, No. of adaptations: 2046 \n",
      "\n",
      "Tables added: 7, Rows added: 1245\n",
      "No. of rows/original books in dict: 813, No. of adaptations: 3917 \n",
      "\n",
      "Tables added: 8, Rows added: 1662\n",
      "No. of rows/original books in dict: 1056, No. of adaptations: 6426 \n",
      "\n",
      "Tables added: 7, Rows added: 2034\n",
      "No. of rows/original books in dict: 1237, No. of adaptations: 9466 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "book_film_dict_all = {}\n",
    "movie_book_dict = {}\n",
    "sum_adaptations = 0\n",
    "\n",
    "for url in wikipages:\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    add_to_rows(soup)\n",
    "    add_to_book_film_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:13:08.195928Z",
     "start_time": "2019-07-16T22:13:08.187229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_initial = len(book_film_dict_all)\n",
    "len_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:13:22.347684Z",
     "start_time": "2019-07-16T22:13:22.338345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'movie_title': '102 Dalmatians', 'book': 'The Hundred and One Dalmatians'},\n",
       " {'movie_title': '3 Godfathers', 'book': 'Three Godfathers'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/102_Dalmatians'], movie_book_dict['https://en.wikipedia.org/wiki/3_Godfathers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:03:55.355138Z",
     "start_time": "2019-07-16T22:03:55.346319Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_isbn(wiki_url):\n",
    "    \"\"\"\n",
    "    Parses the `infobox vcard` element of the wikipedia page of a book, \n",
    "    and returns the 10-digit or 13-digit ISBN number (if found). \n",
    "    \n",
    "    Args:\n",
    "        wiki_url (str): Valid (not local) wikipedia link.\n",
    "\n",
    "    Returns:\n",
    "        isbn: Returns ISBN code is parsed correctly, 'broken' if formmated \n",
    "        incorrectly or otherwise. The code is de-hyphentated for later pipeline\n",
    "        efficiency. \n",
    " \n",
    "    \"\"\"\n",
    "    try:\n",
    "        page = requests.get(wiki_url).text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "    except MissingSchema:\n",
    "        return 'broken'  \n",
    "    \n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "    \n",
    "    if infobox is None:\n",
    "        return 'broken'\n",
    "    \n",
    "    for row in infobox.findAll('tr'):\n",
    "        #ISBN directly available\n",
    "        if ('ISBN' in row.text):\n",
    "            isbn = re.sub('[^0-9]','', row.findAll('a')[-1].text)\n",
    "            return isbn\n",
    "        \n",
    "    #Nothing found directly on Infobox\n",
    "    return 'broken' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:03:59.083488Z",
     "start_time": "2019-07-16T22:03:59.076564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only to be used if get_isbn() returns 'not formatted correctly'\n",
    "def get_oclc(wiki_url):\n",
    "    \"\"\"\n",
    "    Parses the `infobox vcard` element of the wikipedia page of a book, \n",
    "    and returns the 10-digit or 13-digit OCLC number (if found). This function is a backup\n",
    "    if get_isbn() returns 'broken', and must not be relied on. \n",
    "    \n",
    "    Args:\n",
    "        wiki_url (str): Valid (not local) wikipedia link.\n",
    "\n",
    "    Returns:\n",
    "        oclc: Returns OCLC code is parsed correctly, 'broken' if formmated \n",
    "        incorrectly or otherwise. \n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(wiki_url).text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "    except MissingSchema:\n",
    "        return 'broken'\n",
    "\n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "    \n",
    "    if infobox is None:\n",
    "        return 'broken'\n",
    "    \n",
    "    for row in infobox.findAll('tr'):\n",
    "        #only OCLC available\n",
    "        if row.find('a', {'title': 'OCLC'}) is not None:\n",
    "            return (row.find('td').text)\n",
    "        \n",
    "    #Nothing found directly on Infobox\n",
    "    return 'broken'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:05:32.074821Z",
     "start_time": "2019-07-17T00:00:41.945926Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable books: 0, Broken books: 0, Total books: 0\n",
      "Usable books: 51, Broken books: 49, Total books: 100\n",
      "Usable books: 99, Broken books: 101, Total books: 200\n",
      "Usable books: 145, Broken books: 155, Total books: 300\n",
      "Usable books: 175, Broken books: 225, Total books: 400\n",
      "Usable books: 203, Broken books: 297, Total books: 500\n",
      "Usable books: 245, Broken books: 355, Total books: 600\n",
      "Usable books: 293, Broken books: 407, Total books: 700\n",
      "Usable books: 334, Broken books: 466, Total books: 800\n",
      "Usable books: 371, Broken books: 529, Total books: 900\n",
      "Usable books: 406, Broken books: 594, Total books: 1000\n",
      "Usable books: 444, Broken books: 656, Total books: 1100\n",
      "Usable books: 486, Broken books: 714, Total books: 1200\n",
      "Usable books: 501, Broken books: 714, Total books: 1237\n"
     ]
    }
   ],
   "source": [
    "broken_count = 0\n",
    "usable_count = 0\n",
    "index = 0\n",
    "book_film_dict = {}\n",
    "\n",
    "for key in book_film_dict_all.keys():\n",
    "    \n",
    "    link = book_film_dict_all[key]['book_wiki_url']\n",
    "    \n",
    "    try:\n",
    "        book_film_dict_all[key]['isbn'] = get_isbn(link)\n",
    "    \n",
    "        if book_film_dict_all[key]['isbn'] == 'broken':\n",
    "            book_film_dict_all[key]['oclc'] = get_oclc(link)\n",
    "            if book_film_dict_all[key]['oclc'] == 'broken':\n",
    "                book_film_dict_all[key]['valid_identifer'] = False\n",
    "                #Nothing changes, the book is unusable, and the 'usable' flag remains False\n",
    "        else:\n",
    "            book_film_dict_all[key]['valid_identifer'] = True\n",
    "            book_film_dict[key] = copy.deepcopy(book_film_dict_all[key]) #Deepcopy 'true' values to another dictionary\n",
    "            usable_count += 1\n",
    "    except NameError:\n",
    "        pass\n",
    "        \n",
    "    if (index % 100 == 0):\n",
    "        broken_count = index - usable_count\n",
    "        print(\"Usable books: {}, Broken books: {}, Total books: {}\".format(usable_count, broken_count, index))\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "print(\"Usable books: {}, Broken books: {}, Total books: {}\".format(usable_count, broken_count, len_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:05:38.916043Z",
     "start_time": "2019-07-17T00:05:38.908237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 1435)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_film_dict), len(movie_book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:07:18.026976Z",
     "start_time": "2019-07-17T00:07:17.879245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4900115728, 4847924352)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_movie_book_dict = copy.deepcopy(movie_book_dict)\n",
    "id(safe_movie_book_dict), id(movie_book_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we lose a bunch of old books, but it's okay since inflation would have destroyed old movie sales as well. i guess it wokrs out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:31:57.182499Z",
     "start_time": "2019-07-16T22:31:57.173957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Stephen King',\n",
       " 'book_title': 'Dreamcatcher (novel)',\n",
       " 'book_wiki_url': 'https://en.wikipedia.org/wiki/Dreamcatcher_(novel)',\n",
       " 'count': 1,\n",
       " 'adaptations': ['Dreamcatcher (2003 film)'],\n",
       " 'isbn': '9780743211383',\n",
       " 'oclc': '',\n",
       " 'valid_identifier': '',\n",
       " 'valid_identifer': True}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_film_dict['Dreamcatcher (2001)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:32:01.067545Z",
     "start_time": "2019-07-16T22:32:01.052734Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Gulliver's Travels (1726)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-f4f1c0154470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbook_film_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Gulliver's Travels (1726)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: \"Gulliver's Travels (1726)\""
     ]
    }
   ],
   "source": [
    "book_film_dict[\"Gulliver's Travels (1726)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:32:24.379419Z",
     "start_time": "2019-07-16T22:32:24.365960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Jonathan Swift',\n",
       " 'book_title': \"Gulliver's Travels\",\n",
       " 'book_wiki_url': 'https://en.wikipedia.org/wiki/Gulliver%27s_Travels',\n",
       " 'count': 7,\n",
       " 'adaptations': ['Le Voyage de Gulliver à Lilliput et chez les géants (1902 film)',\n",
       "  'The New Gulliver',\n",
       "  \"Gulliver's Travels (1939 film)\",\n",
       "  'The Three Worlds of Gulliver',\n",
       "  \"Gulliver's Travels Beyond the Moon\",\n",
       "  \"Gulliver's Travels (1977 film)\",\n",
       "  \"Gulliver's Travels (2010 film)\"],\n",
       " 'isbn': 'broken',\n",
       " 'oclc': 'broken',\n",
       " 'valid_identifier': '',\n",
       " 'valid_identifer': False}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_film_dict_all[\"Gulliver\\'s Travels (1726)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:32:33.198510Z",
     "start_time": "2019-07-16T22:32:33.186040Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_metadata = ['average_rating', \n",
    "                    'publication_date',\n",
    "                    'rating_dist',\n",
    "                    'ratings_count', 'format',\n",
    "                    'text_reviews_count',\n",
    "                    'title', 'language_code']\n",
    "\n",
    "def get_goodreads_data(gc_code):\n",
    "    \"\"\"\n",
    "    Add additional review and ratings related meta_data from the GoodReads API.\n",
    "    \n",
    "    Args:\n",
    "        gc_code: Strictly Goodreads code. Can be 10-digit or 13-digit.\n",
    "        \n",
    "    Returns:\n",
    "        gr_metadata: Dict with additional metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    gr_metadata = {}\n",
    "    try:\n",
    "        book = gc.book(gc_code)\n",
    "    except NameError:\n",
    "        return gr_metadata\n",
    "    except ExpatError:\n",
    "        return gr_metadata\n",
    "    \n",
    "    for attrs in book.__dict__['_book_dict']:\n",
    "        if attrs in desired_metadata:\n",
    "            gr_metadata['gc_' + attrs] = book.__dict__['_book_dict'][attrs]\n",
    "            \n",
    "    return gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:59:51.081319Z",
     "start_time": "2019-07-17T00:59:51.062358Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "book_metadata_wanted = ['identifiers', 'number_of_pages', 'subject_places', 'subjects', 'publish_date', 'publish_places']\n",
    "\n",
    "def update_book_metadata(book_title):\n",
    "    \"\"\"\n",
    "    Uses the OpenLibrary and Goodreads APIs (when possible) to \n",
    "    add metadata about the books to the `book_film_dict`.\n",
    "    \n",
    "    Args: \n",
    "        book_title: (str) used when merging back into `book_film_dict`.\n",
    "    \n",
    "    Returns:\n",
    "        updated: (bool) True if metadata updated, False otherwise.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    all_metadata = {}\n",
    "    \n",
    "    \n",
    "    if book_film_dict[book_title]['valid_identifer'] is False:\n",
    "        #API can't be accessed\n",
    "        metadata['metadata_updated'] = False\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n",
    "    \n",
    "    elif book_film_dict[book_title]['isbn'] != '':\n",
    "        code = book_film_dict[book_title]['isbn']\n",
    "        curl = 'https://openlibrary.org/api/books?bibkeys=ISBN:{}&jscmd=data&format=json'.format(code)\n",
    "        all_metadata = requests.get(curl).json()\n",
    "    else:\n",
    "        code = book_film_dict[book_title]['oclc']\n",
    "        curl = 'https://openlibrary.org/api/books?bibkeys=OCLC:{}&jscmd=data&format=json'.format(code)\n",
    "        all_metadata = requests.get(curl).json()\n",
    "        \n",
    "    if len(all_metadata) > 0:\n",
    "        key = list(all_metadata.keys())[0]\n",
    "        nested_keys = list(all_metadata[key].keys())\n",
    "        \n",
    "        for data_point in book_metadata_wanted:\n",
    "            if data_point in nested_keys:\n",
    "                metadata[data_point] = all_metadata[key][data_point]\n",
    "    \n",
    "        if 'subject_places' in nested_keys:\n",
    "            metadata['subject_places'] = [place['name'][:30] for place in metadata['subject_places']]\n",
    "        if 'subjects' in nested_keys:\n",
    "            metadata['subjects'] = [subject['name'][:30] for subject in metadata['subjects']]\n",
    "        if 'publish_places' in nested_keys:\n",
    "            metadata['publish_places'] = [place['name'][:30] for place in metadata['publish_places']]            \n",
    "        \n",
    "        if 'identifiers' in nested_keys:\n",
    "            if 'goodreads' in list(metadata['identifiers'].keys()):\n",
    "                metadata['goodreads'] = metadata['identifiers']['goodreads'][0]\n",
    "            metadata.pop('identifiers')\n",
    "            \n",
    "        if 'goodreads' in metadata.keys():\n",
    "            metadata.update(get_goodreads_data(metadata['goodreads']))\n",
    "            \n",
    "        metadata['metadata_updated'] = True\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        metadata['metadata_updated'] = False\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:32:44.333476Z",
     "start_time": "2019-07-16T22:32:43.182607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Stephen King',\n",
       " 'book_title': 'Dreamcatcher (novel)',\n",
       " 'book_wiki_url': 'https://en.wikipedia.org/wiki/Dreamcatcher_(novel)',\n",
       " 'count': 1,\n",
       " 'adaptations': ['Dreamcatcher (2003 film)'],\n",
       " 'isbn': '9780743211383',\n",
       " 'oclc': '',\n",
       " 'valid_identifier': '',\n",
       " 'valid_identifer': True,\n",
       " 'number_of_pages': 620,\n",
       " 'subject_places': ['Maine', 'Derry', 'Hole-in-the-Wall', 'Jefferson Tract'],\n",
       " 'subjects': ['Internet Archive Wishlist',\n",
       "  'male friendship',\n",
       "  'life on other planets',\n",
       "  'telepathy',\n",
       "  'Down Syndrome',\n",
       "  'psychological fiction',\n",
       "  'extraterrestrial beings',\n",
       "  'hunting',\n",
       "  'friendship',\n",
       "  'In library',\n",
       "  'Accessible book',\n",
       "  'Fiction',\n",
       "  'Human-alien encounters',\n",
       "  'Protected DAISY',\n",
       "  'Fear',\n",
       "  'Fantasy Fiction',\n",
       "  'Roman fantastique',\n",
       "  'Audiobooks',\n",
       "  'hunting stories',\n",
       "  'camping',\n",
       "  'Male friendship'],\n",
       " 'publish_date': '2001',\n",
       " 'publish_places': ['New York, USA'],\n",
       " 'goodreads': '441240',\n",
       " 'gc_title': 'Dreamcatcher',\n",
       " 'gc_language_code': 'eng',\n",
       " 'gc_average_rating': '3.62',\n",
       " 'gc_format': 'Hardcover',\n",
       " 'gc_ratings_count': '2021',\n",
       " 'gc_text_reviews_count': '188',\n",
       " 'metadata_updated': True}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_book_metadata('Dreamcatcher (2001)')\n",
    "book_film_dict['Dreamcatcher (2001)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't run below till the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:39:56.323149Z",
     "start_time": "2019-07-16T22:32:52.903565Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed: 75, Updated: 59, Usable: 78.667%\n",
      "Indexed: 150, Updated: 125, Usable: 83.333%\n",
      "Indexed: 225, Updated: 186, Usable: 82.667%\n",
      "Indexed: 300, Updated: 250, Usable: 83.333%\n",
      "Indexed: 375, Updated: 319, Usable: 85.067%\n",
      "Indexed: 450, Updated: 383, Usable: 85.111%\n"
     ]
    }
   ],
   "source": [
    "from xml.parsers.expat import ExpatError\n",
    "\n",
    "metadata_update_count = 0\n",
    "\n",
    "for index, key in enumerate(book_film_dict.keys()):\n",
    "    \n",
    "    if book_film_dict[key]['metadata_updated'] is True:\n",
    "        metadata_update_count += 1\n",
    "    \n",
    "    if index % 75 == 0 and index != 0:\n",
    "        print(\"Indexed: {}, Updated: {}, Usable: {}%\"\n",
    "              .format(index, metadata_update_count, round(100*metadata_update_count/index, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:40:24.064698Z",
     "start_time": "2019-07-16T22:40:24.056126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Started with 1237 rows; now 429 are usable: ~34.681%.\n"
     ]
    }
   ],
   "source": [
    "print(\"Done. Started with {} rows; now {} are usable: ~{}%.\"\n",
    "    .format(len_initial, metadata_update_count, round(100*metadata_update_count/len_initial, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:41:41.106797Z",
     "start_time": "2019-07-16T22:41:41.097976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'A. J. Cronin',\n",
       " 'book_title': 'Grand Canary (novel)',\n",
       " 'book_wiki_url': 'https://en.wikipedia.org/wiki/Grand_Canary_(novel)',\n",
       " 'count': 1,\n",
       " 'adaptations': ['Grand Canary (film)'],\n",
       " 'isbn': '0450020479',\n",
       " 'oclc': '',\n",
       " 'valid_identifier': '',\n",
       " 'valid_identifer': True,\n",
       " 'number_of_pages': 223,\n",
       " 'subject_places': ['Canary Islands',\n",
       "  'Gran Canaria',\n",
       "  'Gran Canaria (Canary Islands)'],\n",
       " 'subjects': ['Fiction', 'Physicians', 'Fiction in English'],\n",
       " 'publish_date': '1975',\n",
       " 'publish_places': ['London'],\n",
       " 'goodreads': '184807',\n",
       " 'metadata_updated': True}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_film_dict['Grand Canary (1933)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:42:25.602808Z",
     "start_time": "2019-07-16T22:42:25.598856Z"
    }
   },
   "source": [
    "## Moving on to movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:44:16.127007Z",
     "start_time": "2019-07-16T22:44:16.118842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': '1984 (1956 film)', 'book': 'Nineteen Eighty-Four'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/1984_(1956_film)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T23:44:23.252840Z",
     "start_time": "2019-07-16T23:44:22.987768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt0413895'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_imdb_no(wiki_movie):\n",
    "    \"\"\"\n",
    "    Returns movie's respective IMDB no (if found). \n",
    "    \n",
    "    Args: \n",
    "        wiki_movie: (str) Wikipedia link of movie's article.\n",
    "        \n",
    "    Returns:\n",
    "        imdb_no: (str) IMDB no. if found, 'broken' otherwise.\n",
    "    \"\"\"\n",
    "    imdb_no = ''   \n",
    "   \n",
    "    try:\n",
    "        page = requests.get(wiki_movie).text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "    except errors:\n",
    "        return 'broken'\n",
    "    \n",
    "    external_links = soup.find('a', href=re.compile(\"imdb.com/title\"))\n",
    "    \n",
    "    try:\n",
    "        imdb_no = external_links['href'].split('/')[4]\n",
    "    except TypeError:\n",
    "        return 'broken'\n",
    "    \n",
    "    return imdb_no\n",
    "    \n",
    "get_imdb_no('https://en.wikipedia.org/wiki/Charlotte%27s_Web_(2006_film)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:27:53.709304Z",
     "start_time": "2019-07-17T00:27:53.690183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1435"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict = copy.deepcopy(safe_movie_book_dict)\n",
    "len(movie_book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:41:45.647898Z",
     "start_time": "2019-07-17T00:37:54.590115Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 150, Usable: 142 --> 94.667%\n",
      "Index: 300, Usable: 283 --> 94.333%\n",
      "Index: 450, Usable: 427 --> 94.889%\n",
      "Index: 600, Usable: 567 --> 94.5%\n",
      "Index: 750, Usable: 712 --> 94.933%\n",
      "Index: 900, Usable: 855 --> 95.0%\n",
      "Index: 1050, Usable: 995 --> 94.762%\n",
      "Index: 1200, Usable: 1139 --> 94.917%\n",
      "Index: 1350, Usable: 1269 --> 94.0%\n"
     ]
    }
   ],
   "source": [
    "from socket import gaierror\n",
    "\n",
    "usable_count = 0\n",
    "errors = (requests.exceptions.MissingSchema or \n",
    "          socket.gaierror or \n",
    "          KeyError or \n",
    "          requests.exceptions.ConnectionError or \n",
    "          requests.exceptions.NewConnectionError or \n",
    "          requests.exceptions.MaxRetryError)\n",
    "\n",
    "for index, key in enumerate(movie_book_dict.keys()):\n",
    "    movie_book_dict[key]['usable'] = False #default is false\n",
    "    \n",
    "    try:\n",
    "        movie_book_dict[key]['imdb_no'] = get_imdb_no(key)\n",
    "    except errors: \n",
    "        movie_book_dict[key]['imdb_no'] = 'broken'\n",
    "    \n",
    "    if movie_book_dict[key]['imdb_no'] != 'broken':\n",
    "        movie_book_dict[key]['usable'] = True\n",
    "        usable_count += 1\n",
    "           \n",
    "    if (index + 1) % 150 == 0:\n",
    "        print('Index: {}, Usable: {} --> {}%'\n",
    "              .format(index + 1, usable_count, round(usable_count*100/(index+1), 3)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T00:44:21.213270Z",
     "start_time": "2019-07-17T00:44:21.201459Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': '1984 (1956 film)',\n",
       " 'book': 'Nineteen Eighty-Four',\n",
       " 'imdb_no': 'tt0048918',\n",
       " 'usable': True}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/1984_(1956_film)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:27:35.182634Z",
     "start_time": "2019-07-17T01:27:35.174132Z"
    }
   },
   "outputs": [],
   "source": [
    "movie_metadata_wanted = ['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', \n",
    "                         'English', 'imdbRating', 'imdbVotes']\n",
    "\n",
    "def add_imdb_metadata(movie_wiki_url):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    all_metadata = {}\n",
    "    imdb_no = movie_book_dict[movie_wiki_url]['imdb_no']\n",
    "    \n",
    "    all_metadata = requests.get('http://www.omdbapi.com/?i={}&apikey=2cb213a7'.format(imdb_no)).json()\n",
    "    \n",
    "    for key in all_metadata.keys():\n",
    "        if key in movie_metadata_wanted:\n",
    "            metadata['imdb_' + key.lower()] = all_metadata[key]\n",
    "            \n",
    "        if 'Actors' in all_metadata.keys():\n",
    "            metadata['imdb_actors'] = get_imdb_actors(all_metadata['Actors'])\n",
    "        if 'Writer' in all_metadata.keys():\n",
    "            metadata['imdb_writers'] = get_imdb_writers(all_metadata['Writer'])\n",
    "            \n",
    "    metadata['metadata_updated'] = True\n",
    "    movie_book_dict[movie_wiki_url].update(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:20:31.905253Z",
     "start_time": "2019-07-17T01:20:31.898979Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_imdb_actors(actor_string):\n",
    "    actors = actor_string.rstrip('.').split(',')\n",
    "    actors = [a.lower().strip() for a in actors]    \n",
    "    return actors\n",
    "\n",
    "def get_imdb_writers(writer_string):\n",
    "    writers = writer_string.rstrip('.').split(',')\n",
    "    writers = [re.sub(r'\\([^()]*\\)', '', w) for w in writers]\n",
    "    writers = [w.lower().strip() for w in writers] \n",
    "    return writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:21:14.979421Z",
     "start_time": "2019-07-17T01:21:14.971343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': 'Jaws (film)',\n",
       " 'book': 'Jaws (novel)',\n",
       " 'imdb_no': 'tt0073195',\n",
       " 'usable': True}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/Jaws_(film)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:21:27.544229Z",
     "start_time": "2019-07-17T01:21:27.365111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': 'Jaws (film)',\n",
       " 'book': 'Jaws (novel)',\n",
       " 'imdb_no': 'tt0073195',\n",
       " 'usable': True,\n",
       " 'imdb_title': 'Jaws',\n",
       " 'imdb_actors': ['roy scheider',\n",
       "  'robert shaw',\n",
       "  'richard dreyfuss',\n",
       "  'lorraine gary'],\n",
       " 'imdb_writers': ['peter benchley', 'carl gottlieb', 'peter benchley'],\n",
       " 'imdb_year': '1975',\n",
       " 'imdb_rated': 'PG',\n",
       " 'imdb_released': '20 Jun 1975',\n",
       " 'imdb_runtime': '124 min',\n",
       " 'imdb_genre': 'Adventure, Drama, Thriller',\n",
       " 'imdb_imdbrating': '8.0',\n",
       " 'imdb_imdbvotes': '511,159',\n",
       " 'metadata_updated': True}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_imdb_metadata('https://en.wikipedia.org/wiki/Jaws_(film)')\n",
    "movie_book_dict['https://en.wikipedia.org/wiki/Jaws_(film)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:34:05.235838Z",
     "start_time": "2019-07-17T01:32:02.751800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 150, Updated: 143 --> 95.33333333333333%\n",
      "Index: 300, Updated: 284 --> 94.66666666666667%\n",
      "Index: 450, Updated: 428 --> 95.11111111111111%\n",
      "Index: 600, Updated: 568 --> 94.66666666666667%\n",
      "Index: 750, Updated: 713 --> 95.06666666666666%\n",
      "Index: 900, Updated: 856 --> 95.11111111111111%\n",
      "Index: 1050, Updated: 996 --> 94.85714285714286%\n",
      "Index: 1200, Updated: 1139 --> 94.91666666666667%\n",
      "Index: 1350, Updated: 1269 --> 94.0%\n",
      "Index: 1434, Updated: 1351 --> 94.21199442119944%\n"
     ]
    }
   ],
   "source": [
    "updated_count = 0\n",
    "for index, key in enumerate(movie_book_dict.keys()):\n",
    "    \n",
    "    if movie_book_dict[key]['usable'] is True:\n",
    "        try:\n",
    "            add_imdb_metadata(key)\n",
    "        except json.JSONDecodeError:\n",
    "            movie_book_dict[key]['usable'] = False\n",
    "            movie_book_dict[key]['imdb_no'] = 'broken'\n",
    "            updated_count -= 1\n",
    "            pass\n",
    "        \n",
    "        updated_count += 1\n",
    "        \n",
    "    if index % 150 == 0 and index != 0:\n",
    "        print('Index: {}, Updated: {} --> {}%'.format(index, updated_count, updated_count * 100/index))\n",
    "        \n",
    "print('Index: {}, Updated: {} --> {}%'.format(index, updated_count, updated_count * 100/index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:34:59.195315Z",
     "start_time": "2019-07-17T01:34:59.187053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': 'It (2017 film)',\n",
       " 'book': 'It (novel)',\n",
       " 'imdb_no': 'tt1396484?d=inprod',\n",
       " 'usable': True,\n",
       " 'metadata_updated': True}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/It_(2017_film)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T01:36:50.470834Z",
     "start_time": "2019-07-17T01:36:50.461722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_title': 'For Whom the Bell Tolls (film)',\n",
       " 'book': 'For Whom the Bell Tolls',\n",
       " 'imdb_no': 'tt0035896',\n",
       " 'usable': True,\n",
       " 'imdb_title': 'For Whom the Bell Tolls',\n",
       " 'imdb_actors': ['gary cooper',\n",
       "  'ingrid bergman',\n",
       "  'akim tamiroff',\n",
       "  'arturo de córdova'],\n",
       " 'imdb_writers': ['dudley nichols', 'ernest hemingway'],\n",
       " 'imdb_year': '1943',\n",
       " 'imdb_rated': 'Passed',\n",
       " 'imdb_released': '28 Apr 1944',\n",
       " 'imdb_runtime': '170 min',\n",
       " 'imdb_genre': 'Adventure, Drama, History, Romance, War',\n",
       " 'imdb_imdbrating': '6.9',\n",
       " 'imdb_imdbvotes': '7,624',\n",
       " 'metadata_updated': True}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['ht']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing in to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.337Z"
    }
   },
   "outputs": [],
   "source": [
    "book_film = pd.DataFrame()\n",
    "rows = []\n",
    "\n",
    "for index, key in enumerate(book_film_dict.keys()):\n",
    "    get_book_metadata(key)\n",
    "    \n",
    "    for movie in book_film_dict[key]['adaptations']:\n",
    "        row = [key, book_film_dict[key]['author'], \n",
    "               movie, \n",
    "               book_film_dict[key]['count'], \n",
    "               book_film_dict[key]['isbn'],\n",
    "               book_film_dict[key]['oclc'],\n",
    "               book_film_dict[key]['usable'],\n",
    "        rows.append(row)\n",
    "        \n",
    "    if index > 20:\n",
    "        break\n",
    "    \n",
    "book_film = pd.DataFrame(data=rows)\n",
    "book_film.rename(columns={0: 'book_title', \n",
    "                          1: 'author', \n",
    "                          2: 'movie', \n",
    "                          3: 'total_ad_count', \n",
    "                          4: 'isbn', 5: 'oclc', \n",
    "                          6: 'usable'},\n",
    "                inplace = True)\n",
    "\n",
    "book_film.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T03:16:51.493642Z",
     "start_time": "2019-07-17T03:16:51.477598Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-e35dfd673896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhamos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mboom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcafe\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhamos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "boom = {'x': 2132, 'y': [1, 2, 4]}\n",
    "cafe = {'x': 43243, 'y': 3}\n",
    "\n",
    "hamos = {'f': boom, 's': cafe}\n",
    "pd.Dataframe.from_dict(hamos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T03:18:10.602968Z",
     "start_time": "2019-07-17T03:18:10.589839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.DataFrame.from_dict(hamos)\n",
    "type(s.iloc[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
