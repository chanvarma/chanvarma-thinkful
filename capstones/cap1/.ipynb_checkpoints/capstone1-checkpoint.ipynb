{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:34.599080Z",
     "start_time": "2019-07-16T22:00:34.594772Z"
    }
   },
   "outputs": [],
   "source": [
    "#re.findall('\\(.*?\\)',b1)\n",
    "#re.findall('\\(.*?\\)',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.294511Z",
     "start_time": "2019-07-16T22:00:40.273243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from goodreads import client\n",
    "gc = client.GoodreadsClient('9addHIFaPJmit7dzC5ZA', 'iDXvx13Rnt1iJkWOxRkSh9wLnbFWmMNgCUMFLJmLPo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.303190Z",
     "start_time": "2019-07-16T22:00:57.297382Z"
    }
   },
   "outputs": [],
   "source": [
    "wikipages = ['https://en.wikipedia.org/wiki/List_of_children%27s_books_made_into_feature_films?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(0%E2%80%939,_A%E2%80%93C)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(D%E2%80%93J)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(K%E2%80%93R)?oldformat=true',\n",
    "             'https://en.wikipedia.org/wiki/List_of_fiction_works_made_into_feature_films_(S%E2%80%93Z)?oldformat=true'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.317754Z",
     "start_time": "2019-07-16T22:00:57.306805Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_rows(page_soup):\n",
    "    \"\"\"\n",
    "    Method extracts row elements from the soup tags of individual \n",
    "    list pages (A - F, H - J, etc.) and appends them to the `rows` \n",
    "    list.\n",
    "    \n",
    "    Args:\n",
    "        page_soup: (BeautifulSoup tag) soup for list page.\n",
    "    \"\"\"\n",
    "    \n",
    "    global rows\n",
    "    \n",
    "    tables = page_soup.find_all('table', {'class': 'wikitable'})\n",
    "\n",
    "    for alphabet in tables:\n",
    "        rows += alphabet.findAll('tr')\n",
    "    \n",
    "    print(\"Tables added: {}, Rows added: {}\".format(len(tables), len(rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:00:57.332827Z",
     "start_time": "2019-07-16T22:00:57.324918Z"
    }
   },
   "outputs": [],
   "source": [
    "def working_wiki_link(wiki_link):\n",
    "    \"\"\"\n",
    "    Converts relative URLs to global URLs.\n",
    "    \"\"\"\n",
    "    \n",
    "    if '/wiki/' in wiki_link:\n",
    "        return 'https://en.wikipedia.org' + wiki_link\n",
    "    return wiki_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:02:03.716547Z",
     "start_time": "2019-07-16T22:01:52.966Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_adaptations(book_title, href_list):\n",
    "    \"\"\"\n",
    "    Parses through list of movies associated with a specific `book_title`,\n",
    "    adds movies to `movie_book_dict`, and returns list of movies.\n",
    "    Adds year to the movie title if information available. \n",
    "    \n",
    "    Args:\n",
    "        book_title: (str) name of original book.\n",
    "        href_list: (list) Result of findAll('a') on the movies column.\n",
    "        \n",
    "    Returns:\n",
    "        adaptations: List of movie title names.\n",
    "    \"\"\"\n",
    "    adaptations = []\n",
    "    \n",
    "    if len(href_list) == 1:\n",
    "        adaptations.append(href_list[0]['title'])\n",
    "        return adaptations\n",
    "        \n",
    "    for index, tag in enumerate(href_list):\n",
    "        year_search = re.search(r'\\d\\d\\d\\d', tag['href'])\n",
    "        \n",
    "        if year_search is not None:  #There is a 4 digit number in the title\n",
    "            year_search = year_search.group()\n",
    "        \n",
    "            if year_search not in tag['title']:\n",
    "                version = tag['title'] + ' (' + year_search + ')'\n",
    "            else:\n",
    "                version = tag['title']\n",
    "            \n",
    "            adaptations.append(version)\n",
    "            movie_book_dict[working_wiki_link(tag['href'])] = {'movie_title': version, \n",
    "                                                              'book': book_title}\n",
    "        \n",
    "        else:\n",
    "            version = tag['title']\n",
    "            adaptations.append(version)\n",
    "            movie_book_dict[working_wiki_link(tag['href'])] = {'movie_title': version, \n",
    "                                                              'book': book_title}\n",
    "\n",
    "    \n",
    "    return adaptations\n",
    "\n",
    "def clean_adaptations(adaptations):\n",
    "    \"\"\"\n",
    "    Makes sure the list of adaptations doesn't contain TV series or miniseries.\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned = []\n",
    "    \n",
    "    for title in adaptations:\n",
    "        if 'TV' in title or 'miniseries' in title:\n",
    "            continue\n",
    "        if 'page does not exist' in title:\n",
    "            continue\n",
    "        else:\n",
    "            cleaned.append(title)\n",
    "            \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:02:08.423130Z",
     "start_time": "2019-07-16T22:02:08.411228Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_book_film_dict():\n",
    "    \"\"\"\n",
    "    Method parses newly updated rows for book/film title, book author,\n",
    "    number of adaptions, and list of adaptations, and adds them to the\n",
    "    `book_film_dict` as a nested dictionary. \n",
    "    global sum_adaptations\n",
    "    \"\"\"\n",
    "    global sum_adaptations\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.findAll('td')\n",
    "\n",
    "        try:\n",
    "            if (len(cols[0].findAll('a')) == 2) and (cols[1].find('a') is not None):\n",
    "                series = cols[0].text.replace('\\n', '').split(',')[0]\n",
    "\n",
    "                book_title = cols[0].findAll('a')[0]['title']\n",
    "                author = cols[0].findAll('a')[-1]['title']\n",
    "\n",
    "                book_wiki_url = working_wiki_link(cols[0].findAll('a')[0]['href'])\n",
    "\n",
    "                try:\n",
    "                    adaptations = clean_adaptations(get_adaptations(book_title, cols[1].findAll('a')))\n",
    "                except KeyError:\n",
    "                    adaptations = []\n",
    "                    pass\n",
    "\n",
    "                sum_adaptations += len(adaptations)\n",
    "\n",
    "                book_film_dict[series] = {'author': author,\n",
    "                                            'book_title': book_title,\n",
    "                                            'book_wiki_url': book_wiki_url,\n",
    "                                            'count': len(adaptations),\n",
    "                                            'adaptations': adaptations,\n",
    "                                            'isbn': '', 'oclc':'', 'valid_identifier': ''}\n",
    "\n",
    "        except IndexError or KeyError:\n",
    "            pass\n",
    "        \n",
    "    print(\"No. of rows/original books in dict: {}, No. of adaptations: {} \\n\"\n",
    "          .format(len(book_film_dict), sum_adaptations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:02:29.987256Z",
     "start_time": "2019-07-16T22:02:24.131295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables added: 25, Rows added: 376\n",
      "No. of rows/original books in dict: 259, No. of adaptations: 754 \n",
      "\n",
      "Tables added: 3, Rows added: 798\n",
      "No. of rows/original books in dict: 553, No. of adaptations: 2046 \n",
      "\n",
      "Tables added: 7, Rows added: 1245\n",
      "No. of rows/original books in dict: 813, No. of adaptations: 3917 \n",
      "\n",
      "Tables added: 8, Rows added: 1662\n",
      "No. of rows/original books in dict: 1056, No. of adaptations: 6426 \n",
      "\n",
      "Tables added: 7, Rows added: 2034\n",
      "No. of rows/original books in dict: 1237, No. of adaptations: 9466 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "book_film_dict = {}\n",
    "movie_book_dict = {}\n",
    "sum_adaptations = 0\n",
    "\n",
    "for url in wikipages:\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    add_to_rows(soup)\n",
    "    add_to_book_film_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:02:59.213467Z",
     "start_time": "2019-07-16T22:02:59.205037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_initial = len(rows)\n",
    "len_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T22:03:25.250445Z",
     "start_time": "2019-07-16T22:03:25.241388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'movie_title': '102 Dalmatians', 'book': 'The Hundred and One Dalmatians'},\n",
       " {'movie_title': '3 Godfathers', 'book': 'Three Godfathers'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_book_dict['https://en.wikipedia.org/wiki/102_Dalmatians'], movie_book_dict['https://en.wikipedia.org/wiki/3_Godfathers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.291Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_isbn(wiki_url):\n",
    "    \"\"\"\n",
    "    Parses the `infobox vcard` element of the wikipedia page of a book, \n",
    "    and returns the 10-digit or 13-digit ISBN number (if found). \n",
    "    \n",
    "    Args:\n",
    "        wiki_url (str): Valid (not local) wikipedia link.\n",
    "\n",
    "    Returns:\n",
    "        isbn: Returns ISBN code is parsed correctly, 'broken' if formmated \n",
    "        incorrectly or otherwise. The code is de-hyphentated for later pipeline\n",
    "        efficiency. \n",
    " \n",
    "    \"\"\"\n",
    "    try:\n",
    "        page = requests.get(wiki_url).text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "    except MissingSchema:\n",
    "        return 'broken'  \n",
    "    \n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "    \n",
    "    if infobox is None:\n",
    "        return 'broken'\n",
    "    \n",
    "    for row in infobox.findAll('tr'):\n",
    "        #ISBN directly available\n",
    "        if ('ISBN' in row.text):\n",
    "            isbn = re.sub('[^0-9]','', row.findAll('a')[-1].text)\n",
    "            return isbn\n",
    "        \n",
    "    #Nothing found directly on Infobox\n",
    "    return 'broken' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only to be used if get_isbn() returns 'not formatted correctly'\n",
    "def get_oclc(wiki_url):\n",
    "    \"\"\"\n",
    "    Parses the `infobox vcard` element of the wikipedia page of a book, \n",
    "    and returns the 10-digit or 13-digit OCLC number (if found). This function is a backup\n",
    "    if get_isbn() returns 'broken', and must not be relied on. \n",
    "    \n",
    "    Args:\n",
    "        wiki_url (str): Valid (not local) wikipedia link.\n",
    "\n",
    "    Returns:\n",
    "        oclc: Returns OCLC code is parsed correctly, 'broken' if formmated \n",
    "        incorrectly or otherwise. \n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(wiki_url).text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "    except MissingSchema:\n",
    "        return 'broken'\n",
    "\n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "    \n",
    "    if infobox is None:\n",
    "        return 'broken'\n",
    "    \n",
    "    for row in infobox.findAll('tr'):\n",
    "        #only OCLC available\n",
    "        if row.find('a', {'title': 'OCLC'}) is not None:\n",
    "            return (row.find('td').text)\n",
    "        \n",
    "    #Nothing found directly on Infobox\n",
    "    return 'broken'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.297Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable: 0, Broken: 0, Total: 0\n",
      "Usable: 25, Broken: 25, Total: 50\n",
      "Usable: 52, Broken: 48, Total: 100\n",
      "Usable: 76, Broken: 74, Total: 150\n"
     ]
    }
   ],
   "source": [
    "broken_count = 0\n",
    "usable_count = 0\n",
    "index = 0\n",
    "\n",
    "for key in book_film_dict.keys():\n",
    "    \n",
    "    link = book_film_dict[key]['book_wiki_url']\n",
    "    \n",
    "    try:\n",
    "        book_film_dict[key]['isbn'] = get_isbn(link)\n",
    "    \n",
    "        if book_film_dict[key]['isbn'] == 'broken':\n",
    "            book_film_dict[key]['oclc'] = get_oclc(link)\n",
    "            if book_film_dict[key]['oclc'] == 'broken':\n",
    "                book_film_dict[key]['valid_identifer'] = False\n",
    "                #Nothing changes, the book is unusable, and the 'usable' flag remains False\n",
    "        else:\n",
    "            book_film_dict[key]['valid_identifer'] = True\n",
    "            usable_count += 1\n",
    "    except NameError:\n",
    "        pass\n",
    "        \n",
    "    if (index % 50 == 0):\n",
    "        broken_count = index - usable_count\n",
    "        print(\"Usable: {}, Broken: {}, Total: {}\".format(usable_count, broken_count, index))\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we lose a bunch of old books, but it's okay since inflation would have destroyed old movie sales as well. i guess it wokrs out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't touch above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.300Z"
    }
   },
   "outputs": [],
   "source": [
    "book_film_dict['Dreamcatcher (2001)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.303Z"
    }
   },
   "outputs": [],
   "source": [
    "book_film_dict[\"Gulliver's Travels (1726)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.306Z"
    }
   },
   "outputs": [],
   "source": [
    "desired_metadata = ['average_rating', \n",
    "                    'publication_date',\n",
    "                    'rating_dist',\n",
    "                    'ratings_count', 'format',\n",
    "                    'text_reviews_count',\n",
    "                    'title', 'language_code']\n",
    "\n",
    "def get_goodreads_data(gc_code):\n",
    "    \"\"\"\n",
    "    Add additional review and ratings related meta_data from the GoodReads API.\n",
    "    \n",
    "    Args:\n",
    "        gc_code: Strictly Goodreads code. Can be 10-digit or 13-digit.\n",
    "        \n",
    "    Returns:\n",
    "        gr_metadata: Dict with additional metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    gr_metadata = {}\n",
    "    try:\n",
    "        book = gc.book(gc_code)\n",
    "    except NameError:\n",
    "        return gr_metadata\n",
    "    except ExpatError:\n",
    "        return gr_metadata\n",
    "    \n",
    "    for attrs in book.__dict__['_book_dict']:\n",
    "        if attrs in desired_metadata:\n",
    "            gr_metadata['gc_' + attrs] = book.__dict__['_book_dict'][attrs]\n",
    "            \n",
    "    return gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.308Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta_data_wanted = ['identifiers', 'number_of_pages', 'subject_places', 'subjects', 'publish_date', 'publish_places']\n",
    "\n",
    "def update_book_metadata(book_title):\n",
    "    \"\"\"\n",
    "    Uses the OpenLibrary and Goodreads APIs (when possible) to \n",
    "    add metadata about the books to the `book_film_dict`.\n",
    "    \n",
    "    Args: \n",
    "        book_title: (str) used when merging back into `book_film_dict`.\n",
    "    \n",
    "    Returns:\n",
    "        updated: (bool) True if metadata updated, False otherwise.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    all_metadata = {}\n",
    "    \n",
    "    \n",
    "    if book_film_dict[book_title]['valid_identifer'] is False:\n",
    "        #API can't be accessed\n",
    "        metadata['metadata_updated'] = False\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n",
    "    \n",
    "    elif book_film_dict[book_title]['isbn'] != '':\n",
    "        code = book_film_dict[book_title]['isbn']\n",
    "        curl = 'https://openlibrary.org/api/books?bibkeys=ISBN:{}&jscmd=data&format=json'.format(code)\n",
    "        all_metadata = requests.get(curl).json()\n",
    "    else:\n",
    "        code = book_film_dict[book_title]['oclc']\n",
    "        curl = 'https://openlibrary.org/api/books?bibkeys=OCLC:{}&jscmd=data&format=json'.format(code)\n",
    "        all_metadata = requests.get(curl).json()\n",
    "        \n",
    "    if len(all_metadata) > 0:\n",
    "        key = list(all_metadata.keys())[0]\n",
    "        nested_keys = list(all_metadata[key].keys())\n",
    "        \n",
    "        for data_point in meta_data_wanted:\n",
    "            if data_point in nested_keys:\n",
    "                metadata[data_point] = all_metadata[key][data_point]\n",
    "    \n",
    "        if 'subject_places' in nested_keys:\n",
    "            metadata['subject_places'] = [place['name'][:30] for place in metadata['subject_places']]\n",
    "        if 'subjects' in nested_keys:\n",
    "            metadata['subjects'] = [subject['name'][:30] for subject in metadata['subjects']]\n",
    "        if 'publish_places' in nested_keys:\n",
    "            metadata['publish_places'] = [place['name'][:30] for place in metadata['publish_places']]            \n",
    "        \n",
    "        if 'identifiers' in nested_keys:\n",
    "            if 'goodreads' in list(metadata['identifiers'].keys()):\n",
    "                metadata['goodreads'] = metadata['identifiers']['goodreads'][0]\n",
    "            metadata.pop('identifiers')\n",
    "            \n",
    "        if 'goodreads' in metadata.keys():\n",
    "            metadata.update(get_goodreads_data(metadata['goodreads']))\n",
    "            \n",
    "        metadata['metadata_updated'] = True\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        metadata['metadata_updated'] = False\n",
    "        book_film_dict[book_title].update(metadata)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.311Z"
    }
   },
   "outputs": [],
   "source": [
    "update_book_metadata('Dreamcatcher (2001)')\n",
    "book_film_dict['Dreamcatcher (2001)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't run below till the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.314Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from xml.parsers.expat import ExpatError\n",
    "\n",
    "metadata_update_count = 0\n",
    "metadate_update_dict = {}\n",
    "\n",
    "for index, key in enumerate(book_film_dict.keys()):\n",
    "    \n",
    "    update_book_metadata(key)\n",
    "    \n",
    "    if book_film_dict[key]['metadata_updated'] is True:\n",
    "        metadata_update_count += 1\n",
    "        \n",
    "    metadate_update_dict[index] = metadata_update_count\n",
    "    \n",
    "    if index % 75 == 0 and index != 0:\n",
    "        print(\"Indexed: {}, Updated: {}, Usable: {}%\"\n",
    "              .format(index, metadata_update_count, round(100*metadata_update_count/index, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.316Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Done. Started with {} rows; now {} are usable: ~{}%.\"\n",
    "    .format(len(book_film_dict), metadata_update_count,round(100*metadata_update_count/len(book_film_dict), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing in to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.333Z"
    }
   },
   "outputs": [],
   "source": [
    "book_film_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T22:00:40.337Z"
    }
   },
   "outputs": [],
   "source": [
    "book_film = pd.DataFrame()\n",
    "rows = []\n",
    "\n",
    "for index, key in enumerate(book_film_dict.keys()):\n",
    "    get_book_metadata(key)\n",
    "    \n",
    "    for movie in book_film_dict[key]['adaptations']:\n",
    "        row = [key, book_film_dict[key]['author'], \n",
    "               movie, \n",
    "               book_film_dict[key]['count'], \n",
    "               book_film_dict[key]['isbn'],\n",
    "               book_film_dict[key]['oclc'],\n",
    "               book_film_dict[key]['usable'],\n",
    "        rows.append(row)\n",
    "        \n",
    "    if index > 20:\n",
    "        break\n",
    "    \n",
    "book_film = pd.DataFrame(data=rows)\n",
    "book_film.rename(columns={0: 'book_title', \n",
    "                          1: 'author', \n",
    "                          2: 'movie', \n",
    "                          3: 'total_ad_count', \n",
    "                          4: 'isbn', 5: 'oclc', \n",
    "                          6: 'usable'},\n",
    "                inplace = True)\n",
    "\n",
    "book_film.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
