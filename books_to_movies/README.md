* **Data wrangling** code (contains API calls, webscraping functions + basic data cleaning)
  *  `.py` file — [here](https://github.com/chanvarma/thinkful-capstones/blob/master/books_to_movies/data_wrangling.py)
  * `.ipynb` file — [here](https://github.com/chanvarma/thinkful-capstones/blob/master/books_to_movies/data_wrangling.ipynb) (large file containing print outputs that are 2000+ lines, and is primarily a workbook that is not formatted for viewing on github)
* Main project workbook (contains project introduction, research questions, data visualisation and inferences)
  * `.ipynb` file — [here](https://github.com/chanvarma/thinkful-capstones/blob/master/books_to_movies/data_viz.ipynb)
  * `.html` file — [here](https://github.com/chanvarma/thinkful-capstones/blob/master/books_to_movies/data_viz.html) > Right Click on 'View raw' > 'Save Link As...' > Open in a web browser of choice
  
---

## Introduction

I've always been deeply fascinated by movies that are adapted from book series. As a bibliophile, it gives immense pleasure to see some of your favorite characters (heroes and villains alike!) represented in visual and tangible form. At the same time, there's perhaps the universal debate that follows about whether the "book was better than the movie", or (in some very rare cases), the opposite. 

I wanted to explore a small section of movies that were adapted from books in an attempt to figuring out if I could isolate some insight that might be helpful for movie studios, and hopefully, the average movie-watcher like you or me. 

### Research questions:
* What factors determine a book's relative rating?
* What does the relative popularity of movie genres looks like over time?
* Which actor can stake a claim for the most successful adaptation actor?
* Can we isolate a collection of movies that must-watch adaptions that are not carried by the book they were adapted from?

### Personal goals for project
On a personal level, I wanted to do work on three skills for this capstone: 
* Build my own dataset, and walk through some of decision making that comes with such a process
* Enrich the data using publicly available APIs, and fill in data gaps with web-scraping 

